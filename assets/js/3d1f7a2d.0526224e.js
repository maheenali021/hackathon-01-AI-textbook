"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[137],{7811:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>g,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module1/bridging-python-agents","title":"Chapter 6: Bridging Python Agents with ROS 2","description":"Introduction to Python Agent Integration","source":"@site/docs/module1/bridging-python-agents.md","sourceDirName":"module1","slug":"/module1/bridging-python-agents","permalink":"/hackathon-01-AI-textbook/docs/module1/bridging-python-agents","draft":false,"unlisted":false,"editUrl":"https://github.com/maheenali021/hackathon-01-AI-textbook/tree/main/docs/module1/bridging-python-agents.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Chapter 6: Bridging Python Agents with ROS 2"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Services and Actions for Robot Control","permalink":"/hackathon-01-AI-textbook/docs/module1/services-actions-control"},"next":{"title":"Chapter 7: Understanding URDF for Humanoid Robots","permalink":"/hackathon-01-AI-textbook/docs/module1/understanding-urdf"}}');var a=t(4848),i=t(8453);const s={sidebar_position:6,title:"Chapter 6: Bridging Python Agents with ROS 2"},o="Bridging Python Agents with ROS 2",l={},c=[{value:"Introduction to Python Agent Integration",id:"introduction-to-python-agent-integration",level:2},{value:"AI Agent Architecture with ROS 2",id:"ai-agent-architecture-with-ros-2",level:2},{value:"Agent-Environment Interface",id:"agent-environment-interface",level:3},{value:"Integration with Popular AI Libraries",id:"integration-with-popular-ai-libraries",level:2},{value:"Using OpenAI Gym for Training",id:"using-openai-gym-for-training",level:3},{value:"Integration with Transformers",id:"integration-with-transformers",level:3},{value:"Advanced Agent Patterns",id:"advanced-agent-patterns",level:2},{value:"Hierarchical Agent Architecture",id:"hierarchical-agent-architecture",level:3},{value:"Multi-Agent Coordination",id:"multi-agent-coordination",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Threading and Concurrency",id:"threading-and-concurrency",level:3},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Hands-on Exercise",id:"hands-on-exercise",level:2}];function d(n){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"bridging-python-agents-with-ros-2",children:"Bridging Python Agents with ROS 2"})}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-python-agent-integration",children:"Introduction to Python Agent Integration"}),"\n",(0,a.jsx)(e.p,{children:"Modern robotics increasingly involves AI agents that can reason, plan, and make decisions. This chapter covers how to bridge Python-based AI agents with ROS 2 for intelligent robot control."}),"\n",(0,a.jsx)(e.h2,{id:"ai-agent-architecture-with-ros-2",children:"AI Agent Architecture with ROS 2"}),"\n",(0,a.jsx)(e.h3,{id:"agent-environment-interface",children:"Agent-Environment Interface"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import LaserScan, Image\nfrom geometry_msgs.msg import Twist\nimport numpy as np\nimport json\n\nclass AgentBridgeNode(Node):\n    def __init__(self):\n        super().__init__('agent_bridge_node')\n\n        # Publishers for robot commands\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Subscribers for sensor data\n        self.laser_sub = self.create_subscription(\n            LaserScan, '/scan', self.laser_callback, 10)\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.image_callback, 10)\n\n        # Agent state\n        self.sensors = {\n            'laser': None,\n            'image': None,\n            'position': None\n        }\n\n        # Timer for agent execution\n        self.agent_timer = self.create_timer(0.1, self.agent_step)\n\n        self.get_logger().info('Agent bridge initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser scan data for the agent\"\"\"\n        self.sensors['laser'] = {\n            'ranges': list(msg.ranges),\n            'min_range': msg.range_min,\n            'max_range': msg.range_max\n        }\n\n    def image_callback(self, msg):\n        \"\"\"Process image data for the agent\"\"\"\n        # Convert ROS Image to numpy array for processing\n        # (simplified - actual conversion depends on encoding)\n        self.sensors['image'] = {\n            'width': msg.width,\n            'height': msg.height,\n            'encoding': msg.encoding\n        }\n\n    def agent_step(self):\n        \"\"\"Execute one step of the AI agent\"\"\"\n        if all(self.sensors.values()):  # All sensors have data\n            # Get action from agent\n            action = self.run_agent_policy(self.sensors)\n\n            # Execute action\n            self.execute_action(action)\n\n    def run_agent_policy(self, observation):\n        \"\"\"Placeholder for AI agent policy - in real implementation, this would use ML models\"\"\"\n        # Simple obstacle avoidance policy\n        if self.sensors['laser']:\n            min_distance = min(self.sensors['laser']['ranges'])\n            if min_distance < 0.5:  # Obstacle too close\n                return {'linear': 0.0, 'angular': 0.5}  # Turn\n            else:\n                return {'linear': 0.3, 'angular': 0.0}  # Move forward\n        return {'linear': 0.0, 'angular': 0.0}  # Stop\n\n    def execute_action(self, action):\n        \"\"\"Execute the action returned by the agent\"\"\"\n        cmd = Twist()\n        cmd.linear.x = action['linear']\n        cmd.angular.z = action['angular']\n        self.cmd_vel_pub.publish(cmd)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"integration-with-popular-ai-libraries",children:"Integration with Popular AI Libraries"}),"\n",(0,a.jsx)(e.h3,{id:"using-openai-gym-for-training",children:"Using OpenAI Gym for Training"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import gym\nfrom gym import spaces\nimport numpy as np\n\nclass ROS2GymEnvironment(gym.Env):\n    """Gym environment wrapper for ROS 2 robot control"""\n\n    def __init__(self, node):\n        super(ROS2GymEnvironment, self).__init__()\n\n        # Define action and observation spaces\n        self.action_space = spaces.Box(\n            low=np.array([-1.0, -1.0]),\n            high=np.array([1.0, 1.0]),\n            dtype=np.float32\n        )\n\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(360,),  # 360 laser ranges\n            dtype=np.float32\n        )\n\n        self.node = node\n        self.current_obs = None\n\n    def step(self, action):\n        # Execute action in ROS 2\n        cmd = Twist()\n        cmd.linear.x = action[0]\n        cmd.angular.z = action[1]\n        self.node.cmd_vel_pub.publish(cmd)\n\n        # Wait for next observation\n        self.current_obs = self.node.sensors[\'laser\'][\'ranges\'] if self.node.sensors[\'laser\'] else [0]*360\n\n        # Calculate reward (simple example)\n        reward = self.calculate_reward(action)\n        done = self.is_done()\n        info = {}\n\n        return np.array(self.current_obs), reward, done, info\n\n    def reset(self):\n        # Reset environment\n        return np.array(self.current_obs)\n\n    def calculate_reward(self, action):\n        """Calculate reward based on action and sensor data"""\n        # Simple reward: positive for moving forward when safe, negative for collisions\n        if self.current_obs and min(self.current_obs) < 0.3:  # Collision risk\n            return -10.0 if action[0] > 0 else 0.0  # Penalty for moving forward near obstacles\n        return action[0] * 0.1  # Small reward for forward movement\n\n    def is_done(self):\n        """Check if episode is done"""\n        if self.current_obs and min(self.current_obs) < 0.2:  # Collision\n            return True\n        return False\n'})}),"\n",(0,a.jsx)(e.h3,{id:"integration-with-transformers",children:"Integration with Transformers"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from transformers import pipeline\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\n\nclass NLPRobotController(Node):\n    def __init__(self):\n        super().__init__('nlp_robot_controller')\n\n        # Initialize NLP pipeline\n        self.nlp_pipeline = pipeline(\"text-classification\",\n                                   model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n\n        # Command recognition\n        self.command_sub = self.create_subscription(\n            String, 'voice_commands', self.command_callback, 10)\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Define command mappings\n        self.command_map = {\n            'forward': {'linear': 0.5, 'angular': 0.0},\n            'backward': {'linear': -0.5, 'angular': 0.0},\n            'left': {'linear': 0.0, 'angular': 0.5},\n            'right': {'linear': 0.0, 'angular': -0.5},\n            'stop': {'linear': 0.0, 'angular': 0.0}\n        }\n\n    def command_callback(self, msg):\n        \"\"\"Process natural language commands\"\"\"\n        command_text = msg.data.lower()\n\n        # Simple keyword matching (in practice, use more sophisticated NLP)\n        recognized_command = self.recognize_command(command_text)\n\n        if recognized_command in self.command_map:\n            action = self.command_map[recognized_command]\n            self.execute_command(action)\n            self.get_logger().info(f'Executed command: {recognized_command}')\n        else:\n            self.get_logger().info(f'Unknown command: {command_text}')\n\n    def recognize_command(self, text):\n        \"\"\"Simple command recognition\"\"\"\n        if 'forward' in text or 'go' in text or 'move' in text:\n            return 'forward'\n        elif 'backward' in text or 'back' in text:\n            return 'backward'\n        elif 'left' in text:\n            return 'left'\n        elif 'right' in text:\n            return 'right'\n        elif 'stop' in text or 'halt' in text:\n            return 'stop'\n        return 'unknown'\n"})}),"\n",(0,a.jsx)(e.h2,{id:"advanced-agent-patterns",children:"Advanced Agent Patterns"}),"\n",(0,a.jsx)(e.h3,{id:"hierarchical-agent-architecture",children:"Hierarchical Agent Architecture"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class HierarchicalAgent(Node):\n    def __init__(self):\n        super().__init__('hierarchical_agent')\n\n        # High-level planner\n        self.planner = HighLevelPlanner()\n\n        # Low-level controller\n        self.controller = LowLevelController()\n\n        # State machine\n        self.current_state = 'IDLE'\n        self.goal = None\n\n        self.state_timer = self.create_timer(0.1, self.state_machine)\n\n    def state_machine(self):\n        \"\"\"Main state machine for hierarchical agent\"\"\"\n        if self.current_state == 'IDLE':\n            new_goal = self.planner.get_next_goal()\n            if new_goal:\n                self.goal = new_goal\n                self.current_state = 'NAVIGATING'\n\n        elif self.current_state == 'NAVIGATING':\n            status = self.controller.navigate_to(self.goal)\n            if status == 'SUCCESS':\n                self.current_state = 'IDLE'\n            elif status == 'FAILED':\n                self.current_state = 'IDLE'  # Retry or plan alternative\n"})}),"\n",(0,a.jsx)(e.h3,{id:"multi-agent-coordination",children:"Multi-Agent Coordination"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from std_msgs.msg import String\nimport json\n\nclass MultiAgentCoordinator(Node):\n    def __init__(self):\n        super().__init__('multi_agent_coordinator')\n\n        # Communication with other agents\n        self.agent_status_sub = self.create_subscription(\n            String, 'agent_status', self.agent_status_callback, 10)\n        self.task_assignment_pub = self.create_publisher(\n            String, 'task_assignment', 10)\n\n        # Agent registry\n        self.agents = {}\n        self.tasks = []\n\n    def agent_status_callback(self, msg):\n        \"\"\"Process status from other agents\"\"\"\n        status = json.loads(msg.data)\n        agent_id = status['agent_id']\n        self.agents[agent_id] = status\n\n    def assign_task(self, task):\n        \"\"\"Assign task to most suitable agent\"\"\"\n        best_agent = self.find_best_agent_for_task(task)\n        if best_agent:\n            assignment = {\n                'agent_id': best_agent,\n                'task': task\n            }\n            assignment_msg = String()\n            assignment_msg.data = json.dumps(assignment)\n            self.task_assignment_pub.publish(assignment_msg)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,a.jsx)(e.h3,{id:"threading-and-concurrency",children:"Threading and Concurrency"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import threading\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass ThreadedAgent(Node):\n    def __init__(self):\n        super().__init__(\'threaded_agent\')\n\n        # Use thread pool for AI computations\n        self.executor = ThreadPoolExecutor(max_workers=2)\n\n        # Thread-safe data structures\n        self.observation_lock = threading.Lock()\n        self.current_observation = None\n\n    def async_ai_processing(self, observation):\n        """Run AI processing in separate thread"""\n        future = self.executor.submit(self.ai_model.predict, observation)\n        return future\n'})}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Bridge Python AI agents with ROS 2 systems"}),"\n",(0,a.jsx)(e.li,{children:"Integrate popular AI libraries with ROS 2"}),"\n",(0,a.jsx)(e.li,{children:"Implement hierarchical agent architectures"}),"\n",(0,a.jsx)(e.li,{children:"Design multi-agent coordination systems"}),"\n",(0,a.jsx)(e.li,{children:"Consider performance implications of AI integration"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-on Exercise"}),"\n",(0,a.jsx)(e.p,{children:"Create a simple AI agent that uses sensor data to navigate a room and avoid obstacles. Implement both a basic rule-based agent and explore using a machine learning model for decision making."}),"\n",(0,a.jsx)(e.admonition,{type:"tip",children:(0,a.jsxs)(e.p,{children:["Use ",(0,a.jsx)(e.code,{children:"rclpy.qos.QoSProfile"})," with appropriate settings to balance performance and reliability when bridging AI agents with ROS 2."]})}),"\n",(0,a.jsx)(e.admonition,{type:"warning",children:(0,a.jsx)(e.p,{children:"Be mindful of computational resources when running AI models on robots. Consider the trade-off between intelligence and real-time performance."})})]})}function g(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>o});var r=t(6540);const a={},i=r.createContext(a);function s(n){const e=r.useContext(i);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),r.createElement(i.Provider,{value:e},n.children)}}}]);