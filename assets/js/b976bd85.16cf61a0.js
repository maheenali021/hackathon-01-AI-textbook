"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[476],{2241:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module4/cognitive-planning","title":"Chapter 3: Cognitive Planning with Large Language Models","description":"Introduction to Cognitive Planning","source":"@site/docs/module4/cognitive-planning.md","sourceDirName":"module4","slug":"/module4/cognitive-planning","permalink":"/hackathon-01-AI-textbook/docs/module4/cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/maheenali021/hackathon-01-AI-textbook/tree/main/docs/module4/cognitive-planning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Chapter 3: Cognitive Planning with Large Language Models"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Voice-to-Action with OpenAI Whisper","permalink":"/hackathon-01-AI-textbook/docs/module4/voice-to-action"},"next":{"title":"Chapter 4: Multi-Modal Integration for VLA Systems","permalink":"/hackathon-01-AI-textbook/docs/module4/multi-modal-integration"}}');var a=t(4848),i=t(8453);const o={sidebar_position:3,title:"Chapter 3: Cognitive Planning with Large Language Models"},s="Cognitive Planning with Large Language Models",l={},c=[{value:"Introduction to Cognitive Planning",id:"introduction-to-cognitive-planning",level:2},{value:"Planning Architecture with LLMs",id:"planning-architecture-with-llms",level:2},{value:"Cognitive Planning Pipeline",id:"cognitive-planning-pipeline",level:3},{value:"Hierarchical Task Planning",id:"hierarchical-task-planning",level:2},{value:"High-Level Task Decomposition",id:"high-level-task-decomposition",level:3},{value:"Symbolic Reasoning and Knowledge Representation",id:"symbolic-reasoning-and-knowledge-representation",level:2},{value:"Knowledge Graph Integration",id:"knowledge-graph-integration",level:3},{value:"Planning with Uncertainty",id:"planning-with-uncertainty",level:2},{value:"Probabilistic Planning",id:"probabilistic-planning",level:3},{value:"Learning from Execution",id:"learning-from-execution",level:2},{value:"Plan Refinement and Adaptation",id:"plan-refinement-and-adaptation",level:3},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Hands-on Exercise",id:"hands-on-exercise",level:2}];function p(n){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"cognitive-planning-with-large-language-models",children:"Cognitive Planning with Large Language Models"})}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-cognitive-planning",children:"Introduction to Cognitive Planning"}),"\n",(0,a.jsx)(e.p,{children:"Cognitive planning in robotics involves using artificial intelligence to create high-level plans that allow robots to achieve complex goals. Large Language Models (LLMs) provide new opportunities for robots to understand natural language commands and generate executable plans."}),"\n",(0,a.jsx)(e.h2,{id:"planning-architecture-with-llms",children:"Planning Architecture with LLMs"}),"\n",(0,a.jsx)(e.h3,{id:"cognitive-planning-pipeline",children:"Cognitive Planning Pipeline"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import PoseStamped\r\nfrom action_msgs.msg import GoalStatus\r\nfrom rclpy.action import ActionClient\r\nfrom nav2_msgs.action import NavigateToPose\r\nimport openai\r\nimport json\r\nimport re\r\nfrom typing import List, Dict, Any\r\n\r\nclass CognitivePlanningNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'cognitive_planning_node\')\r\n\r\n        # Subscribers for natural language commands\r\n        self.command_sub = self.create_subscription(\r\n            String, \'natural_language_commands\', self.command_callback, 10)\r\n\r\n        # Publishers for plan status and feedback\r\n        self.plan_status_pub = self.create_publisher(String, \'plan_status\', 10)\r\n        self.feedback_pub = self.create_publisher(String, \'planning_feedback\', 10)\r\n\r\n        # Action clients for robot execution\r\n        self.nav_client = ActionClient(self, NavigateToPose, \'navigate_to_pose\')\r\n\r\n        # LLM configuration\r\n        self.llm_model = "gpt-3.5-turbo"  # or "gpt-4" for more complex tasks\r\n        self.max_tokens = 1000\r\n        self.temperature = 0.1  # Low temperature for more deterministic planning\r\n\r\n        # Robot state and capabilities\r\n        self.robot_capabilities = [\r\n            "navigation", "manipulation", "perception",\r\n            "communication", "grasping", "transporting"\r\n        ]\r\n\r\n        # Environment representation\r\n        self.environment_map = self.initialize_environment_map()\r\n        self.known_objects = self.initialize_known_objects()\r\n        self.known_locations = self.initialize_known_locations()\r\n\r\n        self.get_logger().info(\'Cognitive planning node initialized\')\r\n\r\n    def initialize_environment_map(self):\r\n        """Initialize environment map with known locations"""\r\n        return {\r\n            "kitchen": {"x": 1.0, "y": 2.0, "theta": 0.0},\r\n            "living_room": {"x": 3.0, "y": 1.0, "theta": 0.0},\r\n            "bedroom": {"x": 5.0, "y": 3.0, "theta": 0.0},\r\n            "office": {"x": 2.0, "y": 5.0, "theta": 0.0},\r\n            "charging_station": {"x": 0.0, "y": 0.0, "theta": 0.0}\r\n        }\r\n\r\n    def initialize_known_objects(self):\r\n        """Initialize known objects in the environment"""\r\n        return {\r\n            "cup": {"type": "drinkware", "graspable": True},\r\n            "book": {"type": "reading_material", "graspable": True},\r\n            "phone": {"type": "electronics", "graspable": True},\r\n            "keys": {"type": "personal_item", "graspable": True},\r\n            "water_bottle": {"type": "drinkware", "graspable": True}\r\n        }\r\n\r\n    def initialize_known_locations(self):\r\n        """Initialize known object locations"""\r\n        return {\r\n            "kitchen_counter": ["cup", "water_bottle"],\r\n            "coffee_table": ["book", "phone"],\r\n            "desk": ["keys", "book"],\r\n            "bedside_table": ["phone", "book"]\r\n        }\r\n\r\n    def command_callback(self, msg):\r\n        """Process natural language command"""\r\n        command = msg.data\r\n        self.get_logger().info(f\'Received command: {command}\')\r\n\r\n        # Generate plan using LLM\r\n        plan = self.generate_plan_with_llm(command)\r\n\r\n        if plan:\r\n            self.execute_plan(plan)\r\n        else:\r\n            self.get_logger().error(f\'Could not generate plan for command: {command}\')\r\n\r\n    def generate_plan_with_llm(self, command: str) -> List[Dict[str, Any]]:\r\n        """Generate a plan using Large Language Model"""\r\n        try:\r\n            # Construct prompt for the LLM\r\n            prompt = self.construct_planning_prompt(command)\r\n\r\n            # Call the LLM (this would use your API key in practice)\r\n            response = self.call_llm(prompt)\r\n\r\n            # Parse the response into a structured plan\r\n            plan = self.parse_llm_response(response)\r\n\r\n            self.get_logger().info(f\'Generated plan: {plan}\')\r\n            return plan\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error generating plan: {e}\')\r\n            return None\r\n\r\n    def construct_planning_prompt(self, command: str) -> str:\r\n        """Construct the prompt for the LLM"""\r\n        prompt = f"""\r\n        You are a cognitive planning system for a household robot. Your task is to create a detailed execution plan for the given command.\r\n\r\n        Current environment knowledge:\r\n        - Locations: {list(self.environment_map.keys())}\r\n        - Known objects: {list(self.known_objects.keys())}\r\n        - Object locations: {self.known_locations}\r\n        - Robot capabilities: {self.robot_capabilities}\r\n\r\n        Command: "{command}"\r\n\r\n        Please provide a step-by-step plan in JSON format with the following structure:\r\n        {{\r\n            "steps": [\r\n                {{\r\n                    "step_number": 1,\r\n                    "action": "action_name",\r\n                    "target_object": "object_name",\r\n                    "target_location": "location_name",\r\n                    "description": "Detailed description of the step",\r\n                    "dependencies": ["previous_step_numbers_if_any"]\r\n                }}\r\n            ],\r\n            "estimated_duration": "Estimated time in seconds",\r\n            "potential_issues": ["List of potential issues"]\r\n        }}\r\n\r\n        The available actions are: navigate_to, pick_up, place_down, detect_object, communicate, wait, charge_battery\r\n        """\r\n\r\n        return prompt\r\n\r\n    def call_llm(self, prompt: str) -> str:\r\n        """Call the Large Language Model"""\r\n        # In a real implementation, this would call the LLM API\r\n        # For this example, we\'ll simulate a response\r\n        return self.simulate_llm_response(prompt)\r\n\r\n    def simulate_llm_response(self, prompt: str) -> str:\r\n        """Simulate LLM response for demonstration"""\r\n        # This is a simplified simulation\r\n        # In practice, you would call the actual LLM API\r\n        if "bring me the cup" in prompt.lower():\r\n            return json.dumps({\r\n                "steps": [\r\n                    {\r\n                        "step_number": 1,\r\n                        "action": "navigate_to",\r\n                        "target_location": "kitchen",\r\n                        "description": "Navigate to the kitchen to find the cup",\r\n                        "dependencies": []\r\n                    },\r\n                    {\r\n                        "step_number": 2,\r\n                        "action": "detect_object",\r\n                        "target_object": "cup",\r\n                        "description": "Detect and locate the cup on the counter",\r\n                        "dependencies": [1]\r\n                    },\r\n                    {\r\n                        "step_number": 3,\r\n                        "action": "pick_up",\r\n                        "target_object": "cup",\r\n                        "description": "Pick up the cup from the counter",\r\n                        "dependencies": [2]\r\n                    },\r\n                    {\r\n                        "step_number": 4,\r\n                        "action": "navigate_to",\r\n                        "target_location": "user_location",\r\n                        "description": "Navigate back to the user with the cup",\r\n                        "dependencies": [3]\r\n                    },\r\n                    {\r\n                        "step_number": 5,\r\n                        "action": "place_down",\r\n                        "target_object": "cup",\r\n                        "description": "Place the cup down near the user",\r\n                        "dependencies": [4]\r\n                    }\r\n                ],\r\n                "estimated_duration": "120",\r\n                "potential_issues": ["Cup might not be in expected location", "Path might be blocked"]\r\n            })\r\n        else:\r\n            # Default response for other commands\r\n            return json.dumps({\r\n                "steps": [],\r\n                "estimated_duration": "0",\r\n                "potential_issues": ["Command not understood"]\r\n            })\r\n\r\n    def parse_llm_response(self, response: str) -> List[Dict[str, Any]]:\r\n        """Parse the LLM response into a structured plan"""\r\n        try:\r\n            parsed_response = json.loads(response)\r\n            return parsed_response.get(\'steps\', [])\r\n        except json.JSONDecodeError:\r\n            self.get_logger().error(f\'Could not parse LLM response: {response}\')\r\n            return None\r\n\r\n    def execute_plan(self, plan: List[Dict[str, Any]]):\r\n        """Execute the generated plan"""\r\n        self.get_logger().info(f\'Executing plan with {len(plan)} steps\')\r\n\r\n        for step in plan:\r\n            success = self.execute_plan_step(step)\r\n            if not success:\r\n                self.get_logger().error(f\'Plan execution failed at step: {step}\')\r\n                break\r\n\r\n        self.get_logger().info(\'Plan execution completed\')\r\n\r\n    def execute_plan_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute a single step of the plan"""\r\n        action = step[\'action\']\r\n        self.get_logger().info(f\'Executing step {step["step_number"]}: {action}\')\r\n\r\n        if action == \'navigate_to\':\r\n            return self.execute_navigation_step(step)\r\n        elif action == \'pick_up\':\r\n            return self.execute_pickup_step(step)\r\n        elif action == \'place_down\':\r\n            return self.execute_placement_step(step)\r\n        elif action == \'detect_object\':\r\n            return self.execute_detection_step(step)\r\n        elif action == \'communicate\':\r\n            return self.execute_communication_step(step)\r\n        elif action == \'wait\':\r\n            return self.execute_wait_step(step)\r\n        elif action == \'charge_battery\':\r\n            return self.execute_charging_step(step)\r\n        else:\r\n            self.get_logger().error(f\'Unknown action: {action}\')\r\n            return False\r\n\r\n    def execute_navigation_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute navigation step"""\r\n        target_location = step[\'target_location\']\r\n\r\n        if target_location == \'user_location\':\r\n            # In practice, this would get user location from localization\r\n            target_pose = self.get_user_location()\r\n        else:\r\n            location_data = self.environment_map.get(target_location)\r\n            if not location_data:\r\n                self.get_logger().error(f\'Unknown location: {target_location}\')\r\n                return False\r\n\r\n            target_pose = self.create_pose_stamped(\r\n                location_data[\'x\'],\r\n                location_data[\'y\'],\r\n                location_data[\'theta\']\r\n            )\r\n\r\n        return self.navigate_to_pose(target_pose)\r\n\r\n    def execute_pickup_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute pickup step"""\r\n        target_object = step[\'target_object\']\r\n        self.get_logger().info(f\'Attempting to pick up {target_object}\')\r\n\r\n        # In practice, this would involve manipulation\r\n        # For simulation, we\'ll just return success\r\n        return True\r\n\r\n    def execute_placement_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute placement step"""\r\n        target_object = step[\'target_object\']\r\n        self.get_logger().info(f\'Attempting to place down {target_object}\')\r\n\r\n        # In practice, this would involve manipulation\r\n        # For simulation, we\'ll just return success\r\n        return True\r\n\r\n    def execute_detection_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute object detection step"""\r\n        target_object = step[\'target_object\']\r\n        self.get_logger().info(f\'Attempting to detect {target_object}\')\r\n\r\n        # In practice, this would use perception systems\r\n        # For simulation, assume object is detected\r\n        return True\r\n\r\n    def execute_communication_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute communication step"""\r\n        description = step[\'description\']\r\n        self.get_logger().info(f\'Communicating: {description}\')\r\n\r\n        # In practice, this might use text-to-speech\r\n        return True\r\n\r\n    def execute_wait_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute wait step"""\r\n        # In practice, this would wait for a condition\r\n        return True\r\n\r\n    def execute_charging_step(self, step: Dict[str, Any]) -> bool:\r\n        """Execute charging step"""\r\n        return self.navigate_to_pose(self.get_charging_station_pose())\r\n\r\n    def navigate_to_pose(self, pose: PoseStamped) -> bool:\r\n        """Navigate to the specified pose using Navigation2"""\r\n        if not self.nav_client.wait_for_server(timeout_sec=5.0):\r\n            self.get_logger().error(\'Navigation action server not available\')\r\n            return False\r\n\r\n        goal_msg = NavigateToPose.Goal()\r\n        goal_msg.pose = pose\r\n\r\n        future = self.nav_client.send_goal_async(goal_msg)\r\n        rclpy.spin_until_future_complete(self, future)\r\n\r\n        result = future.result()\r\n        if result is not None:\r\n            return True\r\n        else:\r\n            self.get_logger().error(\'Navigation failed\')\r\n            return False\r\n\r\n    def create_pose_stamped(self, x: float, y: float, theta: float) -> PoseStamped:\r\n        """Create a PoseStamped message from coordinates"""\r\n        pose = PoseStamped()\r\n        pose.header.stamp = self.get_clock().now().to_msg()\r\n        pose.header.frame_id = \'map\'\r\n        pose.pose.position.x = x\r\n        pose.pose.position.y = y\r\n        pose.pose.position.z = 0.0\r\n\r\n        # Convert theta to quaternion\r\n        import math\r\n        sin_half_theta = math.sin(theta / 2.0)\r\n        cos_half_theta = math.cos(theta / 2.0)\r\n        pose.pose.orientation.x = 0.0\r\n        pose.pose.orientation.y = 0.0\r\n        pose.pose.orientation.z = sin_half_theta\r\n        pose.pose.orientation.w = cos_half_theta\r\n\r\n        return pose\r\n\r\n    def get_user_location(self) -> PoseStamped:\r\n        """Get user location (in practice, this would come from localization)"""\r\n        # For simulation, return a default user location\r\n        return self.create_pose_stamped(0.0, 0.0, 0.0)\r\n\r\n    def get_charging_station_pose(self) -> PoseStamped:\r\n        """Get charging station pose"""\r\n        charging_data = self.environment_map[\'charging_station\']\r\n        return self.create_pose_stamped(\r\n            charging_data[\'x\'],\r\n            charging_data[\'y\'],\r\n            charging_data[\'theta\']\r\n        )\n'})}),"\n",(0,a.jsx)(e.h2,{id:"hierarchical-task-planning",children:"Hierarchical Task Planning"}),"\n",(0,a.jsx)(e.h3,{id:"high-level-task-decomposition",children:"High-Level Task Decomposition"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class HierarchicalPlanner:\r\n    def __init__(self):\r\n        self.task_library = self.initialize_task_library()\r\n\r\n    def initialize_task_library(self):\r\n        """Initialize a library of known tasks and their decompositions"""\r\n        return {\r\n            "fetch_object": {\r\n                "description": "Fetch an object from one location to another",\r\n                "subtasks": [\r\n                    {"action": "navigate_to", "params": ["source_location"]},\r\n                    {"action": "detect_object", "params": ["object_name"]},\r\n                    {"action": "pick_up", "params": ["object_name"]},\r\n                    {"action": "navigate_to", "params": ["destination_location"]},\r\n                    {"action": "place_down", "params": ["object_name"]}\r\n                ]\r\n            },\r\n            "clean_surface": {\r\n                "description": "Clean a surface by removing objects",\r\n                "subtasks": [\r\n                    {"action": "navigate_to", "params": ["surface_location"]},\r\n                    {"action": "detect_objects", "params": ["surface_location"]},\r\n                    {"action": "pick_up", "params": ["object_name"]},\r\n                    {"action": "navigate_to", "params": ["storage_location"]},\r\n                    {"action": "place_down", "params": ["object_name"]}\r\n                ]\r\n            },\r\n            "set_table": {\r\n                "description": "Set a table with specific items",\r\n                "subtasks": [\r\n                    {"action": "navigate_to", "params": ["storage_location"]},\r\n                    {"action": "pick_up", "params": ["item_name"]},\r\n                    {"action": "navigate_to", "params": ["table_location"]},\r\n                    {"action": "place_down", "params": ["item_name"]}\r\n                ]\r\n            }\r\n        }\r\n\r\n    def decompose_task(self, task_name: str, params: Dict[str, Any]) -> List[Dict[str, Any]]:\r\n        """Decompose a high-level task into primitive actions"""\r\n        if task_name not in self.task_library:\r\n            raise ValueError(f"Unknown task: {task_name}")\r\n\r\n        template = self.task_library[task_name]\r\n        subtasks = []\r\n\r\n        for i, subtask_template in enumerate(template["subtasks"]):\r\n            subtask = {\r\n                "step_number": i + 1,\r\n                "action": subtask_template["action"],\r\n                "description": f"Execute {subtask_template[\'action\']} for {task_name}",\r\n                "dependencies": [i] if i > 0 else []\r\n            }\r\n\r\n            # Bind parameters\r\n            for param_name in subtask_template["params"]:\r\n                if param_name in params:\r\n                    subtask[param_name] = params[param_name]\r\n                else:\r\n                    # Use default or raise error\r\n                    subtask[param_name] = f"default_{param_name}"\r\n\r\n            subtasks.append(subtask)\r\n\r\n        return subtasks\n'})}),"\n",(0,a.jsx)(e.h2,{id:"symbolic-reasoning-and-knowledge-representation",children:"Symbolic Reasoning and Knowledge Representation"}),"\n",(0,a.jsx)(e.h3,{id:"knowledge-graph-integration",children:"Knowledge Graph Integration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from typing import Set, Tuple\r\n\r\nclass KnowledgeGraph:\r\n    def __init__(self):\r\n        self.entities = set()\r\n        self.relations = set()\r\n        self.facts = set()\r\n\r\n    def add_entity(self, entity: str, entity_type: str):\r\n        """Add an entity to the knowledge graph"""\r\n        self.entities.add((entity, entity_type))\r\n\r\n    def add_relation(self, subject: str, predicate: str, obj: str):\r\n        """Add a relation between entities"""\r\n        fact = (subject, predicate, obj)\r\n        self.facts.add(fact)\r\n\r\n    def query(self, subject: str, predicate: str = None, obj: str = None) -> Set[Tuple]:\r\n        """Query the knowledge graph"""\r\n        results = set()\r\n\r\n        for fact in self.facts:\r\n            s, p, o = fact\r\n            if (subject is None or s == subject) and \\\r\n               (predicate is None or p == predicate) and \\\r\n               (obj is None or o == obj):\r\n                results.add(fact)\r\n\r\n        return results\r\n\r\n    def get_related_entities(self, entity: str) -> Set[str]:\r\n        """Get entities related to the given entity"""\r\n        related = set()\r\n\r\n        for fact in self.facts:\r\n            s, p, o = fact\r\n            if s == entity:\r\n                related.add(o)\r\n            elif o == entity:\r\n                related.add(s)\r\n\r\n        return related\r\n\r\nclass SemanticPlanner(Node):\r\n    def __init__(self):\r\n        super().__init__(\'semantic_planner\')\r\n        self.knowledge_graph = KnowledgeGraph()\r\n        self.build_initial_knowledge()\r\n\r\n    def build_initial_knowledge(self):\r\n        """Build initial knowledge base"""\r\n        # Add locations\r\n        locations = ["kitchen", "living_room", "bedroom", "office", "hallway"]\r\n        for loc in locations:\r\n            self.knowledge_graph.add_entity(loc, "location")\r\n\r\n        # Add objects\r\n        objects = ["cup", "book", "phone", "keys", "water_bottle", "plate", "fork"]\r\n        for obj in objects:\r\n            self.knowledge_graph.add_entity(obj, "object")\r\n\r\n        # Add relations\r\n        self.knowledge_graph.add_relation("kitchen", "contains", "cup")\r\n        self.knowledge_graph.add_relation("kitchen", "contains", "plate")\r\n        self.knowledge_graph.add_relation("kitchen", "contains", "fork")\r\n        self.knowledge_graph.add_relation("living_room", "contains", "book")\r\n        self.knowledge_graph.add_relation("office", "contains", "phone")\r\n        self.knowledge_graph.add_relation("bedroom", "contains", "keys")\r\n\r\n        # Add object affordances\r\n        graspable_objects = ["cup", "book", "phone", "keys", "water_bottle", "plate", "fork"]\r\n        for obj in graspable_objects:\r\n            self.knowledge_graph.add_relation(obj, "affordance", "graspable")\r\n\r\n    def semantic_query_planning(self, command: str) -> List[Dict[str, Any]]:\r\n        """Use semantic knowledge to inform planning"""\r\n        # Parse command to extract key entities\r\n        entities = self.extract_entities(command)\r\n\r\n        # Query knowledge graph for relevant information\r\n        plan_steps = []\r\n        for entity in entities:\r\n            related_facts = self.knowledge_graph.query(subject=entity)\r\n\r\n            for fact in related_facts:\r\n                _, predicate, obj = fact\r\n                if predicate == "contains":\r\n                    # Plan to navigate to the location containing the object\r\n                    plan_steps.extend([\r\n                        {\r\n                            "action": "navigate_to",\r\n                            "target_location": obj,\r\n                            "description": f"Navigate to {obj} where {entity} is located"\r\n                        },\r\n                        {\r\n                            "action": "detect_object",\r\n                            "target_object": entity,\r\n                            "description": f"Detect {entity} in {obj}"\r\n                        }\r\n                    ])\r\n\r\n        return plan_steps\r\n\r\n    def extract_entities(self, command: str) -> List[str]:\r\n        """Extract relevant entities from command"""\r\n        # Simple keyword matching (in practice, use NER)\r\n        entities = []\r\n        words = command.lower().split()\r\n\r\n        for word in words:\r\n            # Remove punctuation\r\n            clean_word = word.strip(\'.,!?\')\r\n            if clean_word in [entity for entity, _ in self.knowledge_graph.entities]:\r\n                entities.append(clean_word)\r\n\r\n        return entities\n'})}),"\n",(0,a.jsx)(e.h2,{id:"planning-with-uncertainty",children:"Planning with Uncertainty"}),"\n",(0,a.jsx)(e.h3,{id:"probabilistic-planning",children:"Probabilistic Planning"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nfrom typing import Optional\r\n\r\nclass ProbabilisticPlanner:\r\n    def __init__(self):\r\n        self.action_success_probabilities = {\r\n            "navigate_to": 0.95,\r\n            "detect_object": 0.85,\r\n            "pick_up": 0.90,\r\n            "place_down": 0.95,\r\n            "communicate": 0.99\r\n        }\r\n\r\n        self.object_location_probabilities = self.initialize_location_probabilities()\r\n\r\n    def initialize_location_probabilities(self):\r\n        """Initialize probabilities of objects being in locations"""\r\n        return {\r\n            "cup": {"kitchen": 0.8, "office": 0.1, "bedroom": 0.1},\r\n            "book": {"living_room": 0.6, "office": 0.3, "bedroom": 0.1},\r\n            "phone": {"office": 0.4, "bedroom": 0.4, "living_room": 0.2},\r\n            "keys": {"bedroom": 0.5, "office": 0.3, "kitchen": 0.2},\r\n            "water_bottle": {"kitchen": 0.7, "office": 0.2, "living_room": 0.1}\r\n        }\r\n\r\n    def probabilistic_plan_generation(self, command: str) -> List[Dict[str, Any]]:\r\n        """Generate plan considering action and state uncertainties"""\r\n        # Extract target object from command\r\n        target_object = self.extract_target_object(command)\r\n\r\n        if not target_object:\r\n            return []\r\n\r\n        # Find most probable location for the object\r\n        location_probs = self.object_location_probabilities.get(target_object, {})\r\n        if not location_probs:\r\n            return []\r\n\r\n        # Sort locations by probability (descending)\r\n        sorted_locations = sorted(location_probs.items(), key=lambda x: x[1], reverse=True)\r\n\r\n        plan = []\r\n\r\n        # For each location (starting with most probable)\r\n        for location, prob in sorted_locations:\r\n            # Add navigation and detection steps with success probability\r\n            nav_step = {\r\n                "action": "navigate_to",\r\n                "target_location": location,\r\n                "success_probability": self.action_success_probabilities["navigate_to"],\r\n                "description": f"Navigate to {location} (prob: {prob:.2f})"\r\n            }\r\n\r\n            detect_step = {\r\n                "action": "detect_object",\r\n                "target_object": target_object,\r\n                "success_probability": self.action_success_probabilities["detect_object"] * prob,\r\n                "description": f"Detect {target_object} in {location} (combined prob: {self.action_success_probabilities[\'detect_object\'] * prob:.2f})"\r\n            }\r\n\r\n            plan.extend([nav_step, detect_step])\r\n\r\n        return plan\r\n\r\n    def extract_target_object(self, command: str) -> Optional[str]:\r\n        """Extract target object from command"""\r\n        command_lower = command.lower()\r\n\r\n        # Simple keyword matching (in practice, use better NLU)\r\n        for obj in self.object_location_probabilities.keys():\r\n            if obj in command_lower:\r\n                return obj\r\n\r\n        return None\r\n\r\n    def plan_evaluation(self, plan: List[Dict[str, Any]]) -> float:\r\n        """Evaluate plan based on success probability"""\r\n        if not plan:\r\n            return 0.0\r\n\r\n        # Calculate overall success probability\r\n        total_prob = 1.0\r\n        for step in plan:\r\n            if "success_probability" in step:\r\n                total_prob *= step["success_probability"]\r\n\r\n        return total_prob\r\n\r\n    def plan_optimization(self, command: str) -> List[Dict[str, Any]]:\r\n        """Optimize plan considering success probabilities"""\r\n        # Generate multiple plan alternatives\r\n        basic_plan = self.probabilistic_plan_generation(command)\r\n\r\n        # Evaluate and potentially refine the plan\r\n        success_prob = self.plan_evaluation(basic_plan)\r\n\r\n        if success_prob < 0.5:  # Threshold for plan quality\r\n            # Add backup plans or alternative routes\r\n            return self.add_backup_strategies(basic_plan, command)\r\n\r\n        return basic_plan\r\n\r\n    def add_backup_strategies(self, plan: List[Dict[str, Any]], command: str) -> List[Dict[str, Any]]:\r\n        """Add backup strategies to improve plan robustness"""\r\n        # Add alternative locations to check if primary locations fail\r\n        # Add verification steps after critical actions\r\n        # Add recovery behaviors\r\n\r\n        enhanced_plan = []\r\n\r\n        for step in plan:\r\n            enhanced_plan.append(step)\r\n\r\n            # Add verification after critical actions\r\n            if step["action"] in ["detect_object", "pick_up", "place_down"]:\r\n                verification_step = {\r\n                    "action": "verify_success",\r\n                    "depends_on": step["action"],\r\n                    "description": f"Verify success of {step[\'action\']}"\r\n                }\r\n                enhanced_plan.append(verification_step)\r\n\r\n        return enhanced_plan\n'})}),"\n",(0,a.jsx)(e.h2,{id:"learning-from-execution",children:"Learning from Execution"}),"\n",(0,a.jsx)(e.h3,{id:"plan-refinement-and-adaptation",children:"Plan Refinement and Adaptation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class AdaptivePlanner(Node):\r\n    def __init__(self):\r\n        super().__init__(\'adaptive_planner\')\r\n\r\n        # Plan execution history\r\n        self.execution_history = []\r\n\r\n        # Learned heuristics\r\n        self.learned_patterns = {}\r\n\r\n        # Performance metrics\r\n        self.performance_stats = {\r\n            "success_rate": {},\r\n            "execution_time": {},\r\n            "failure_modes": {}\r\n        }\r\n\r\n    def record_execution(self, plan: List[Dict[str, Any]],\r\n                         success: bool,\r\n                         execution_time: float,\r\n                         failure_reason: str = None):\r\n        """Record plan execution for learning"""\r\n        execution_record = {\r\n            "plan": plan,\r\n            "success": success,\r\n            "time": execution_time,\r\n            "failure_reason": failure_reason,\r\n            "timestamp": self.get_clock().now().to_msg()\r\n        }\r\n\r\n        self.execution_history.append(execution_record)\r\n\r\n        # Update statistics\r\n        self.update_performance_stats(plan, success, execution_time, failure_reason)\r\n\r\n    def update_performance_stats(self, plan: List[Dict[str, Any]],\r\n                               success: bool,\r\n                               execution_time: float,\r\n                               failure_reason: str = None):\r\n        """Update performance statistics"""\r\n        for step in plan:\r\n            action = step["action"]\r\n\r\n            if action not in self.performance_stats["success_rate"]:\r\n                self.performance_stats["success_rate"][action] = []\r\n                self.performance_stats["execution_time"][action] = []\r\n\r\n            self.performance_stats["success_rate"][action].append(success)\r\n            self.performance_stats["execution_time"][action].append(execution_time)\r\n\r\n        if failure_reason:\r\n            if failure_reason not in self.performance_stats["failure_modes"]:\r\n                self.performance_stats["failure_modes"][failure_reason] = 0\r\n            self.performance_stats["failure_modes"][failure_reason] += 1\r\n\r\n    def adapt_plan(self, command: str, current_plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\r\n        """Adapt plan based on execution history and learned patterns"""\r\n        # Analyze past executions for similar commands\r\n        similar_executions = self.find_similar_executions(command, current_plan)\r\n\r\n        if similar_executions:\r\n            # Apply learned adaptations\r\n            adapted_plan = self.apply_learned_adaptations(current_plan, similar_executions)\r\n            return adapted_plan\r\n\r\n        return current_plan\r\n\r\n    def find_similar_executions(self, command: str, plan: List[Dict[str, Any]]):\r\n        """Find similar past executions"""\r\n        # Simple similarity based on actions and objects\r\n        similar = []\r\n\r\n        for record in self.execution_history:\r\n            # Compare plans based on action sequence and objects\r\n            if self.plans_are_similar(plan, record["plan"]):\r\n                similar.append(record)\r\n\r\n        return similar\r\n\r\n    def plans_are_similar(self, plan1: List[Dict[str, Any]], plan2: List[Dict[str, Any]]) -> bool:\r\n        """Check if two plans are similar"""\r\n        if len(plan1) != len(plan2):\r\n            return False\r\n\r\n        for step1, step2 in zip(plan1, plan2):\r\n            if step1.get("action") != step2.get("action"):\r\n                return False\r\n            if step1.get("target_object") != step2.get("target_object"):\r\n                return False\r\n\r\n        return True\r\n\r\n    def apply_learned_adaptations(self, original_plan: List[Dict[str, Any]],\r\n                                 similar_executions: List[dict]) -> List[Dict[str, Any]]:\r\n        """Apply learned adaptations to the plan"""\r\n        adapted_plan = []\r\n\r\n        for i, step in enumerate(original_plan):\r\n            # Get adaptations for this step type\r\n            step_executions = [ex for ex in similar_executions\r\n                              if i < len(ex["plan"]) and ex["plan"][i]["action"] == step["action"]]\r\n\r\n            if step_executions:\r\n                # Apply successful patterns\r\n                successful_executions = [ex for ex in step_executions if ex["success"]]\r\n\r\n                if len(successful_executions) / len(step_executions) < 0.7:  # Low success rate\r\n                    # Add verification or alternative approach\r\n                    verification_step = {\r\n                        "action": "verify_environment",\r\n                        "description": f"Verify environment before {step[\'action\']} due to low success rate",\r\n                        "critical": True\r\n                    }\r\n                    adapted_plan.append(verification_step)\r\n\r\n            adapted_plan.append(step)\r\n\r\n        return adapted_plan\n'})}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Design cognitive planning systems using Large Language Models"}),"\n",(0,a.jsx)(e.li,{children:"Implement hierarchical task decomposition"}),"\n",(0,a.jsx)(e.li,{children:"Create knowledge representations for robotic planning"}),"\n",(0,a.jsx)(e.li,{children:"Incorporate uncertainty into planning processes"}),"\n",(0,a.jsx)(e.li,{children:"Build adaptive planning systems that learn from execution"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-on Exercise"}),"\n",(0,a.jsx)(e.p,{children:"Create a cognitive planning system that accepts natural language commands and generates executable plans for a simulated robot. Test the system with various commands and evaluate its performance in different scenarios."}),"\n",(0,a.jsx)(e.admonition,{type:"tip",children:(0,a.jsx)(e.p,{children:"Combine LLM-based high-level planning with traditional path planning algorithms for robust navigation tasks."})}),"\n",(0,a.jsx)(e.admonition,{type:"note",children:(0,a.jsx)(e.p,{children:"Consider the computational cost of LLM calls and implement caching mechanisms for frequently requested plans."})})]})}function d(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(p,{...n})}):p(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>o,x:()=>s});var r=t(6540);const a={},i=r.createContext(a);function o(n){const e=r.useContext(i);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),r.createElement(i.Provider,{value:e},n.children)}}}]);