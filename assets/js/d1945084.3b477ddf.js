"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[958],{1470:(e,a,n)=>{n.d(a,{A:()=>S});var i=n(6540),r=n(4164),l=n(7559),t=n(3104),s=n(6347),o=n(205),c=n(7485),d=n(1682),u=n(679);function p(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:a,children:n}=e;return(0,i.useMemo)(()=>{const e=a??function(e){return p(e).map(({props:{value:e,label:a,attributes:n,default:i}})=>({value:e,label:a,attributes:n,default:i}))}(n);return function(e){const a=(0,d.XI)(e,(e,a)=>e.value===a.value);if(a.length>0)throw new Error(`Docusaurus error: Duplicate values "${a.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[a,n])}function m({value:e,tabValues:a}){return a.some(a=>a.value===e)}function f({queryString:e=!1,groupId:a}){const n=(0,s.W6)(),r=function({queryString:e=!1,groupId:a}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:e,groupId:a});return[(0,c.aZ)(r),(0,i.useCallback)(e=>{if(!r)return;const a=new URLSearchParams(n.location.search);a.set(r,e),n.replace({...n.location,search:a.toString()})},[r,n])]}function v(e){const{defaultValue:a,queryString:n=!1,groupId:r}=e,l=h(e),[t,s]=(0,i.useState)(()=>function({defaultValue:e,tabValues:a}){if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${a.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=a.find(e=>e.default)??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:a,tabValues:l})),[c,d]=f({queryString:n,groupId:r}),[p,v]=function({groupId:e}){const a=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,r]=(0,u.Dv)(a);return[n,(0,i.useCallback)(e=>{a&&r.set(e)},[a,r])]}({groupId:r}),g=(()=>{const e=c??p;return m({value:e,tabValues:l})?e:null})();(0,o.A)(()=>{g&&s(g)},[g]);return{selectedValue:t,selectValue:(0,i.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);s(e),d(e),v(e)},[d,v,l]),tabValues:l}}var g=n(2303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=n(4848);function j({className:e,block:a,selectedValue:n,selectValue:i,tabValues:l}){const s=[],{blockElementScrollPositionUntilNextRender:o}=(0,t.a_)(),c=e=>{const a=e.currentTarget,r=s.indexOf(a),t=l[r].value;t!==n&&(o(a),i(t))},d=e=>{let a=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=s.indexOf(e.currentTarget)+1;a=s[n]??s[0];break}case"ArrowLeft":{const n=s.indexOf(e.currentTarget)-1;a=s[n]??s[s.length-1];break}}a?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":a},e),children:l.map(({value:e,label:a,attributes:i})=>(0,b.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{s.push(e)},onKeyDown:d,onClick:c,...i,className:(0,r.A)("tabs__item",x.tabItem,i?.className,{"tabs__item--active":n===e}),children:a??e},e))})}function I({lazy:e,children:a,selectedValue:n}){const l=(Array.isArray(a)?a:[a]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===n);return e?(0,i.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:l.map((e,a)=>(0,i.cloneElement)(e,{key:a,hidden:e.props.value!==n}))})}function _(e){const a=v(e);return(0,b.jsxs)("div",{className:(0,r.A)(l.G.tabs.container,"tabs-container",x.tabList),children:[(0,b.jsx)(j,{...a,...e}),(0,b.jsx)(I,{...a,...e})]})}function S(e){const a=(0,g.A)();return(0,b.jsx)(_,{...e,children:p(e.children)},String(a))}},8453:(e,a,n)=>{n.d(a,{R:()=>t,x:()=>s});var i=n(6540);const r={},l=i.createContext(r);function t(e){const a=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function s(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(l.Provider,{value:a},e.children)}},8892:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"module3/isaac-ros","title":"Chapter 2: Isaac ROS","description":"Hardware-Accelerated VSLAM and Navigation Pipelines","source":"@site/docs/module3/isaac-ros.md","sourceDirName":"module3","slug":"/module3/isaac-ros","permalink":"/hackathon-01-AI-textbook/docs/module3/isaac-ros","draft":false,"unlisted":false,"editUrl":"https://github.com/maheenali021/hackathon-01-AI-textbook/tree/main/docs/module3/isaac-ros.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Chapter 2: Isaac ROS"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Introduction to NVIDIA Isaac","permalink":"/hackathon-01-AI-textbook/docs/module3/intro-to-nvidia-isaac"},"next":{"title":"Chapter 3: Navigation2 Path Planning and Execution","permalink":"/hackathon-01-AI-textbook/docs/module3/nav2-path-planning"}}');var r=n(4848),l=n(8453),t=n(1470),s=n(9365);const o={sidebar_position:2,title:"Chapter 2: Isaac ROS"},c="Isaac ROS",d={},u=[{value:"Hardware-Accelerated VSLAM and Navigation Pipelines",id:"hardware-accelerated-vslam-and-navigation-pipelines",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Hardware Acceleration",id:"hardware-acceleration",level:3},{value:"Perception Pipelines",id:"perception-pipelines",level:3},{value:"Navigation Capabilities",id:"navigation-capabilities",level:3},{value:"Core Packages",id:"core-packages",level:2},{value:"Isaac ROS Visual SLAM",id:"isaac-ros-visual-slam",level:3},{value:"Isaac ROS Apriltag",id:"isaac-ros-apriltag",level:3},{value:"Isaac ROS Stereo DNN",id:"isaac-ros-stereo-dnn",level:3},{value:"Isaac ROS Detection NITROS",id:"isaac-ros-detection-nitros",level:3},{value:"Installation",id:"installation",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Installation via Debian Packages",id:"installation-via-debian-packages",level:3},{value:"Docker Installation",id:"docker-installation",level:3},{value:"Example: Visual SLAM Pipeline",id:"example-visual-slam-pipeline",level:2},{value:"Launch File Configuration",id:"launch-file-configuration",level:3},{value:"Performance Benefits",id:"performance-benefits",level:2},{value:"Computational Efficiency",id:"computational-efficiency",level:3},{value:"Accuracy Improvements",id:"accuracy-improvements",level:3},{value:"Integration with ROS 2 Ecosystem",id:"integration-with-ros-2-ecosystem",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Hands-on Exercise",id:"hands-on-exercise",level:2}];function p(e){const a={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.header,{children:(0,r.jsx)(a.h1,{id:"isaac-ros",children:"Isaac ROS"})}),"\n",(0,r.jsx)(a.h2,{id:"hardware-accelerated-vslam-and-navigation-pipelines",children:"Hardware-Accelerated VSLAM and Navigation Pipelines"}),"\n",(0,r.jsx)(a.p,{children:"Isaac ROS is a collection of hardware-accelerated perception and navigation packages designed for robotics applications. It leverages NVIDIA's GPU and Deep Learning Accelerator (DLA) technologies to provide real-time performance for computationally intensive algorithms."}),"\n",(0,r.jsx)(a.h2,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsx)(a.h3,{id:"hardware-acceleration",children:"Hardware Acceleration"}),"\n",(0,r.jsx)(a.p,{children:"Isaac ROS packages are optimized to run on NVIDIA GPUs and Jetson platforms, providing:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Real-time processing of sensor data"}),"\n",(0,r.jsx)(a.li,{children:"Accelerated computer vision algorithms"}),"\n",(0,r.jsx)(a.li,{children:"GPU-accelerated deep learning inference"}),"\n",(0,r.jsx)(a.li,{children:"Optimized memory management"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"perception-pipelines",children:"Perception Pipelines"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Visual Simultaneous Localization and Mapping (VSLAM)"}),"\n",(0,r.jsx)(a.li,{children:"Object detection and tracking"}),"\n",(0,r.jsx)(a.li,{children:"Depth estimation and stereo processing"}),"\n",(0,r.jsx)(a.li,{children:"Sensor fusion algorithms"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"navigation-capabilities",children:"Navigation Capabilities"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Path planning and obstacle avoidance"}),"\n",(0,r.jsx)(a.li,{children:"Local and global planners optimized for acceleration"}),"\n",(0,r.jsx)(a.li,{children:"Costmap management with GPU acceleration"}),"\n",(0,r.jsx)(a.li,{children:"Controller algorithms for smooth navigation"}),"\n"]}),"\n",(0,r.jsx)(a.h2,{id:"core-packages",children:"Core Packages"}),"\n",(0,r.jsxs)(t.A,{groupId:"isaac-ros-packages",children:[(0,r.jsxs)(s.A,{value:"visual-slam",label:"Visual SLAM",children:[(0,r.jsx)(a.h3,{id:"isaac-ros-visual-slam",children:"Isaac ROS Visual SLAM"}),(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Real-time visual SLAM with GPU acceleration"}),"\n",(0,r.jsx)(a.li,{children:"Support for stereo cameras and RGB-D sensors"}),"\n",(0,r.jsx)(a.li,{children:"Loop closure detection and correction"}),"\n",(0,r.jsx)(a.li,{children:"Map building and localization"}),"\n"]})]}),(0,r.jsxs)(s.A,{value:"apriltag",label:"Apriltag",children:[(0,r.jsx)(a.h3,{id:"isaac-ros-apriltag",children:"Isaac ROS Apriltag"}),(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"High-performance Apriltag detection"}),"\n",(0,r.jsx)(a.li,{children:"GPU-accelerated image processing"}),"\n",(0,r.jsx)(a.li,{children:"Multiple tag detection in a single image"}),"\n",(0,r.jsx)(a.li,{children:"Accurate pose estimation"}),"\n"]})]}),(0,r.jsxs)(s.A,{value:"stereo-dnn",label:"Stereo DNN",children:[(0,r.jsx)(a.h3,{id:"isaac-ros-stereo-dnn",children:"Isaac ROS Stereo DNN"}),(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Real-time stereo depth estimation"}),"\n",(0,r.jsx)(a.li,{children:"Deep neural network acceleration"}),"\n",(0,r.jsx)(a.li,{children:"Obstacle detection and segmentation"}),"\n",(0,r.jsx)(a.li,{children:"Multi-task neural networks"}),"\n"]})]}),(0,r.jsxs)(s.A,{value:"detection-nitros",label:"Detection NITROS",children:[(0,r.jsx)(a.h3,{id:"isaac-ros-detection-nitros",children:"Isaac ROS Detection NITROS"}),(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Hardware-accelerated object detection"}),"\n",(0,r.jsx)(a.li,{children:"NITROS (NVIDIA Isaac Transport for ROS) for optimized data transport"}),"\n",(0,r.jsx)(a.li,{children:"Support for various DNN models"}),"\n",(0,r.jsx)(a.li,{children:"Pipeline optimization for throughput"}),"\n"]})]})]}),"\n",(0,r.jsx)(a.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(a.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"NVIDIA GPU with CUDA support (or Jetson platform)"}),"\n",(0,r.jsx)(a.li,{children:"ROS 2 Humble Hawksbill"}),"\n",(0,r.jsx)(a.li,{children:"CUDA 11.8 or later"}),"\n",(0,r.jsx)(a.li,{children:"NVIDIA Container Toolkit"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"installation-via-debian-packages",children:"Installation via Debian Packages"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-bash",children:"# Add NVIDIA's ROS2 repository\r\nsudo apt update\r\nsudo apt install nvidia-isaac-ros-gxf-dev\r\nsudo apt install nvidia-isaac-ros-common\r\nsudo apt install nvidia-isaac-ros-gems-dev\n"})}),"\n",(0,r.jsx)(a.h3,{id:"docker-installation",children:"Docker Installation"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-bash",children:"# Pull Isaac ROS Docker images\r\ndocker pull nvcr.io/nvidia/isaac-ros/isaac_ros_visual_slam:latest\r\ndocker pull nvcr.io/nvidia/isaac-ros/isaac_ros_apriltag:latest\n"})}),"\n",(0,r.jsx)(a.h2,{id:"example-visual-slam-pipeline",children:"Example: Visual SLAM Pipeline"}),"\n",(0,r.jsx)(a.h3,{id:"launch-file-configuration",children:"Launch File Configuration"}),"\n",(0,r.jsxs)(t.A,{groupId:"slam-configuration",children:[(0,r.jsx)(s.A,{value:"full",label:"Complete Launch File",children:(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-xml",children:'<launch>\r\n  \x3c!-- Visual SLAM node --\x3e\r\n  <node pkg="isaac_ros_visual_slam" exec="visual_slam_node" name="visual_slam_node" output="screen">\r\n    <param name="enable_rectified_pose" value="true"/>\r\n    <param name="map_frame" value="map"/>\r\n    <param name="odom_frame" value="odom"/>\r\n    <param name="base_frame" value="base_link"/>\r\n    <param name="sensor_qos" value="SENSOR_DATA"/>\r\n  </node>\r\n\r\n  \x3c!-- Image Proc for rectification --\x3e\r\n  <node pkg="image_proc" exec="rectify" name="left_rectify_node" output="screen" namespace="camera/left">\r\n    <remap from="image" to="image_raw"/>\r\n    <remap from="camera_info" to="camera_info"/>\r\n  </node>\r\n\r\n  <node pkg="image_proc" exec="rectify" name="right_rectify_node" output="screen" namespace="camera/right">\r\n    <remap from="image" to="image_raw"/>\r\n    <remap from="camera_info" to="camera_info"/>\r\n  </node>\r\n</launch>\n'})})}),(0,r.jsx)(s.A,{value:"slam-node",label:"SLAM Node",children:(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-xml",children:'\x3c!-- Visual SLAM node --\x3e\r\n<node pkg="isaac_ros_visual_slam" exec="visual_slam_node" name="visual_slam_node" output="screen">\r\n  <param name="enable_rectified_pose" value="true"/>\r\n  <param name="map_frame" value="map"/>\r\n  <param name="odom_frame" value="odom"/>\r\n  <param name="base_frame" value="base_link"/>\r\n  <param name="sensor_qos" value="SENSOR_DATA"/>\r\n</node>\n'})})}),(0,r.jsx)(s.A,{value:"image-rect",label:"Image Rectification",children:(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-xml",children:'\x3c!-- Image Proc for rectification --\x3e\r\n<node pkg="image_proc" exec="rectify" name="left_rectify_node" output="screen" namespace="camera/left">\r\n  <remap from="image" to="image_raw"/>\r\n  <remap from="camera_info" to="camera_info"/>\r\n</node>\r\n\r\n<node pkg="image_proc" exec="rectify" name="right_rectify_node" output="screen" namespace="camera/right">\r\n  <remap from="image" to="image_raw"/>\r\n  <remap from="camera_info" to="camera_info"/>\r\n</node>\n'})})})]}),"\n",(0,r.jsx)(a.h2,{id:"performance-benefits",children:"Performance Benefits"}),"\n",(0,r.jsx)(a.h3,{id:"computational-efficiency",children:"Computational Efficiency"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Leverage GPU parallelism for sensor processing"}),"\n",(0,r.jsx)(a.li,{children:"Reduce CPU load for other robot tasks"}),"\n",(0,r.jsx)(a.li,{children:"Achieve real-time performance for complex algorithms"}),"\n",(0,r.jsx)(a.li,{children:"Optimize power consumption on Jetson platforms"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"accuracy-improvements",children:"Accuracy Improvements"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Higher frame rates for better tracking"}),"\n",(0,r.jsx)(a.li,{children:"More sophisticated algorithms within real-time constraints"}),"\n",(0,r.jsx)(a.li,{children:"Better sensor fusion with reduced latency"}),"\n"]}),"\n",(0,r.jsx)(a.h2,{id:"integration-with-ros-2-ecosystem",children:"Integration with ROS 2 Ecosystem"}),"\n",(0,r.jsx)(a.p,{children:"Isaac ROS packages seamlessly integrate with the broader ROS 2 ecosystem:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Standard ROS 2 message types and interfaces"}),"\n",(0,r.jsx)(a.li,{children:"Compatibility with Navigation2 stack"}),"\n",(0,r.jsx)(a.li,{children:"Integration with RViz for visualization"}),"\n",(0,r.jsx)(a.li,{children:"Support for standard robot descriptions (URDF)"}),"\n"]}),"\n",(0,r.jsx)(a.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(a.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Understand the benefits of hardware-accelerated ROS packages"}),"\n",(0,r.jsx)(a.li,{children:"Install and configure Isaac ROS packages"}),"\n",(0,r.jsx)(a.li,{children:"Set up a basic Visual SLAM pipeline"}),"\n",(0,r.jsx)(a.li,{children:"Integrate Isaac ROS with existing ROS 2 systems"}),"\n"]}),"\n",(0,r.jsx)(a.h2,{id:"hands-on-exercise",children:"Hands-on Exercise"}),"\n",(0,r.jsx)(a.p,{children:"Set up a simple Isaac ROS pipeline using one of the available packages (e.g., Isaac ROS Apriltag) and observe the performance benefits compared to CPU-only implementations."})]})}function h(e={}){const{wrapper:a}={...(0,l.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},9365:(e,a,n)=>{n.d(a,{A:()=>t});n(6540);var i=n(4164);const r={tabItem:"tabItem_Ymn6"};var l=n(4848);function t({children:e,hidden:a,className:n}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,i.A)(r.tabItem,n),hidden:a,children:e})}}}]);